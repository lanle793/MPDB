{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess dataframe\n",
    "poster_dir = \"../data/posters/\"\n",
    "poster_df = pd.read_csv(\"../data/MovieGenre.csv\", encoding = \"ISO-8859-1\")\n",
    "poster_df = poster_df.drop_duplicates(subset=['imdbId'], keep=\"last\")\n",
    "poster_df[\"Genre\"] = poster_df[\"Genre\"].str.split(\"|\")\n",
    "poster_df[\"filename\"] = poster_df[\"imdbId\"].astype(str) + \".jpg\"\n",
    "poster_df = poster_df.dropna()\n",
    "poster_df = poster_df[poster_df[\"Genre\"].apply(lambda t: isinstance(t, list))]\n",
    "poster_df = poster_df.iloc[random.sample(range(0, 30000), 5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3486 validated image filenames belonging to 27 classes.\n",
      "Found 1161 validated image filenames belonging to 27 classes.\n",
      "{'Action': 0, 'Adult': 1, 'Adventure': 2, 'Animation': 3, 'Biography': 4, 'Comedy': 5, 'Crime': 6, 'Documentary': 7, 'Drama': 8, 'Family': 9, 'Fantasy': 10, 'Film-Noir': 11, 'Game-Show': 12, 'History': 13, 'Horror': 14, 'Music': 15, 'Musical': 16, 'Mystery': 17, 'News': 18, 'Romance': 19, 'Sci-Fi': 20, 'Short': 21, 'Sport': 22, 'Talk-Show': 23, 'Thriller': 24, 'War': 25, 'Western': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lle\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 353 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lle\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 353 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# create image data generator\n",
    "datagen = ImageDataGenerator(rescale=1./255., validation_split=0.25)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=poster_df,\n",
    "                                              directory=poster_dir,\n",
    "                                              x_col=\"filename\",\n",
    "                                              y_col=\"Genre\",\n",
    "                                              subset=\"training\",\n",
    "                                              batch_size=32,\n",
    "                                              shuffle=True,\n",
    "                                              seed=42,\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              target_size=(64, 64))\n",
    "\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(dataframe=poster_df,\n",
    "                                            directory=poster_dir,\n",
    "                                            x_col=\"filename\",\n",
    "                                            y_col=\"Genre\",\n",
    "                                            subset=\"validation\",\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=True,\n",
    "                                            seed=42,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            target_size=(64, 64))\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "108/108 [==============================] - 5s 40ms/step - loss: 0.5546 - accuracy: 0.0693 - val_loss: 0.2457 - val_accuracy: 0.2422\n",
      "Epoch 2/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.3052 - accuracy: 0.1915 - val_loss: 0.2289 - val_accuracy: 0.2431\n",
      "Epoch 3/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.2689 - accuracy: 0.2284 - val_loss: 0.2246 - val_accuracy: 0.2431\n",
      "Epoch 4/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.2580 - accuracy: 0.2551 - val_loss: 0.2292 - val_accuracy: 0.2422\n",
      "Epoch 5/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.2490 - accuracy: 0.2509 - val_loss: 0.2228 - val_accuracy: 0.2431\n",
      "Epoch 6/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.2447 - accuracy: 0.2546 - val_loss: 0.2209 - val_accuracy: 0.2422\n",
      "Epoch 7/50\n",
      "108/108 [==============================] - 4s 40ms/step - loss: 0.2416 - accuracy: 0.2491 - val_loss: 0.2210 - val_accuracy: 0.2422\n",
      "Epoch 8/50\n",
      "108/108 [==============================] - 4s 39ms/step - loss: 0.2388 - accuracy: 0.2562 - val_loss: 0.2219 - val_accuracy: 0.2413\n",
      "Epoch 9/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.2336 - accuracy: 0.2611 - val_loss: 0.2201 - val_accuracy: 0.2439\n",
      "Epoch 10/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.2346 - accuracy: 0.2558 - val_loss: 0.2200 - val_accuracy: 0.2422\n",
      "Epoch 11/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.2328 - accuracy: 0.2647 - val_loss: 0.2203 - val_accuracy: 0.2439\n",
      "Epoch 12/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.2304 - accuracy: 0.2666 - val_loss: 0.2193 - val_accuracy: 0.2431\n",
      "Epoch 13/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.2312 - accuracy: 0.2519 - val_loss: 0.2192 - val_accuracy: 0.2422\n",
      "Epoch 14/50\n",
      "108/108 [==============================] - 4s 39ms/step - loss: 0.2300 - accuracy: 0.2591 - val_loss: 0.2185 - val_accuracy: 0.2422\n",
      "Epoch 15/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.2297 - accuracy: 0.2637 - val_loss: 0.2184 - val_accuracy: 0.2413\n",
      "Epoch 16/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.2297 - accuracy: 0.2672 - val_loss: 0.2184 - val_accuracy: 0.2422\n",
      "Epoch 17/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.2285 - accuracy: 0.2646 - val_loss: 0.2188 - val_accuracy: 0.2405\n",
      "Epoch 18/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.2279 - accuracy: 0.2604 - val_loss: 0.2179 - val_accuracy: 0.2422\n",
      "Epoch 19/50\n",
      "108/108 [==============================] - 4s 39ms/step - loss: 0.2271 - accuracy: 0.2542 - val_loss: 0.2176 - val_accuracy: 0.2422\n",
      "Epoch 20/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.2250 - accuracy: 0.2634 - val_loss: 0.2174 - val_accuracy: 0.2431\n",
      "Epoch 21/50\n",
      "108/108 [==============================] - 5s 42ms/step - loss: 0.2226 - accuracy: 0.2550 - val_loss: 0.2171 - val_accuracy: 0.2405\n",
      "Epoch 22/50\n",
      "108/108 [==============================] - 4s 37ms/step - loss: 0.2232 - accuracy: 0.2622 - val_loss: 0.2178 - val_accuracy: 0.2413\n",
      "Epoch 23/50\n",
      "108/108 [==============================] - 4s 36ms/step - loss: 0.2232 - accuracy: 0.2660 - val_loss: 0.2173 - val_accuracy: 0.2431\n",
      "Epoch 24/50\n",
      "108/108 [==============================] - 4s 35ms/step - loss: 0.2210 - accuracy: 0.2604 - val_loss: 0.2173 - val_accuracy: 0.2413\n",
      "Epoch 25/50\n",
      "108/108 [==============================] - 4s 37ms/step - loss: 0.2213 - accuracy: 0.2650 - val_loss: 0.2181 - val_accuracy: 0.2422\n",
      "Epoch 26/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.2232 - accuracy: 0.2665 - val_loss: 0.2179 - val_accuracy: 0.2405\n",
      "Epoch 27/50\n",
      "108/108 [==============================] - 4s 35ms/step - loss: 0.2193 - accuracy: 0.2607 - val_loss: 0.2177 - val_accuracy: 0.2396\n",
      "Epoch 28/50\n",
      "108/108 [==============================] - 4s 36ms/step - loss: 0.2203 - accuracy: 0.2730 - val_loss: 0.2189 - val_accuracy: 0.2439\n",
      "Epoch 29/50\n",
      "108/108 [==============================] - 4s 36ms/step - loss: 0.2127 - accuracy: 0.2524 - val_loss: 0.2187 - val_accuracy: 0.2396\n",
      "Epoch 30/50\n",
      "108/108 [==============================] - 4s 36ms/step - loss: 0.2136 - accuracy: 0.2666 - val_loss: 0.2200 - val_accuracy: 0.2439\n",
      "Epoch 31/50\n",
      "108/108 [==============================] - 4s 37ms/step - loss: 0.2138 - accuracy: 0.2599 - val_loss: 0.2230 - val_accuracy: 0.2396\n",
      "Epoch 32/50\n",
      "108/108 [==============================] - 4s 37ms/step - loss: 0.2105 - accuracy: 0.2829 - val_loss: 0.2235 - val_accuracy: 0.2587\n",
      "Epoch 33/50\n",
      "108/108 [==============================] - 4s 35ms/step - loss: 0.2117 - accuracy: 0.2803 - val_loss: 0.2252 - val_accuracy: 0.2500\n",
      "Epoch 34/50\n",
      "108/108 [==============================] - 4s 37ms/step - loss: 0.2093 - accuracy: 0.2994 - val_loss: 0.2238 - val_accuracy: 0.2613\n",
      "Epoch 35/50\n",
      "108/108 [==============================] - 4s 37ms/step - loss: 0.2067 - accuracy: 0.3057 - val_loss: 0.2243 - val_accuracy: 0.2648\n",
      "Epoch 36/50\n",
      "108/108 [==============================] - 4s 36ms/step - loss: 0.2052 - accuracy: 0.2896 - val_loss: 0.2251 - val_accuracy: 0.2700\n",
      "Epoch 37/50\n",
      "108/108 [==============================] - 4s 41ms/step - loss: 0.1986 - accuracy: 0.3020 - val_loss: 0.2318 - val_accuracy: 0.2795\n",
      "Epoch 38/50\n",
      "108/108 [==============================] - 4s 39ms/step - loss: 0.1953 - accuracy: 0.3098 - val_loss: 0.2313 - val_accuracy: 0.2691\n",
      "Epoch 39/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.1903 - accuracy: 0.3266 - val_loss: 0.2336 - val_accuracy: 0.2743\n",
      "Epoch 40/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.1923 - accuracy: 0.3128 - val_loss: 0.2390 - val_accuracy: 0.2873\n",
      "Epoch 41/50\n",
      "108/108 [==============================] - 4s 37ms/step - loss: 0.1848 - accuracy: 0.3409 - val_loss: 0.2423 - val_accuracy: 0.2839\n",
      "Epoch 42/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.1864 - accuracy: 0.3325 - val_loss: 0.2488 - val_accuracy: 0.2743\n",
      "Epoch 43/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.1836 - accuracy: 0.3517 - val_loss: 0.2457 - val_accuracy: 0.2804\n",
      "Epoch 44/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.1823 - accuracy: 0.3642 - val_loss: 0.2479 - val_accuracy: 0.2969\n",
      "Epoch 45/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.1782 - accuracy: 0.3511 - val_loss: 0.2511 - val_accuracy: 0.3056\n",
      "Epoch 46/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.1776 - accuracy: 0.3702 - val_loss: 0.2485 - val_accuracy: 0.2760\n",
      "Epoch 47/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.1824 - accuracy: 0.3794 - val_loss: 0.2531 - val_accuracy: 0.2925\n",
      "Epoch 48/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.1769 - accuracy: 0.3850 - val_loss: 0.2528 - val_accuracy: 0.2812\n",
      "Epoch 49/50\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.1821 - accuracy: 0.3731 - val_loss: 0.2553 - val_accuracy: 0.2943\n",
      "Epoch 50/50\n",
      "108/108 [==============================] - 4s 39ms/step - loss: 0.1742 - accuracy: 0.3846 - val_loss: 0.2566 - val_accuracy: 0.2882\n"
     ]
    }
   ],
   "source": [
    "# use CNN model for classification\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(64,64,3)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "          \n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "adam = Adam(learning_rate=7e-4, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "#callback = EarlyStopping(patience=3)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "history = model.fit(x=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    epochs=50,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model for deployment\n",
    "pickle.dump(model, open('poster_predictor.pkl', 'wb+'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "1. https://godatadriven.com/blog/keras-multi-label-classification-with-imagedatagenerator/\n",
    "2. https://github.com/nddave/Movie-Genre-Prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
